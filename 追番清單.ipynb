{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icecat14159/PL-Repo./blob/main/%E8%BF%BD%E7%95%AA%E6%B8%85%E5%96%AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gspread #GoogleSheet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ll_u9as1owQf",
        "outputId": "e7eaeccb-cb84-45d5-e259-ac984fc149ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.12/dist-packages (6.2.1)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from gspread) (2.43.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GUe08BH2rm1y",
        "outputId": "d5270d27-4331-42c7-ed19-657fea0ce121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas #è³‡æ–™è™•ç†"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Nx8nCM8FrnLo",
        "outputId": "5dd7b702-442b-4316-adc8-31bcd2f8a4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gspread gradio pandas beautifulsoup4 requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBj9adsoYJxJ",
        "outputId": "aadab4c8-9ebc-462f-e150-07d145af7256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.12/dist-packages (6.2.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from gspread) (2.43.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth #èº«åˆ†é©—è­‰\n",
        "from google.auth import default #æ†‘è­‰\n",
        "import gspread\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import datetime #æ—¥æœŸ\n",
        "import io #io\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "!pip install feedparser\n",
        "import feedparser"
      ],
      "metadata": {
        "id": "rxEBQ_40qqsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a41dec-2297-4007-84b4-9dd594983565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.12/dist-packages (6.0.12)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æˆæ¬Šé€£ç·š Google Sheet\n",
        "auth.authenticate_user()  #è¦æ±‚æˆæ¬Š\n",
        "creds, _ = default()  #ç²å–æ†‘è­‰\n",
        "gc = gspread.authorize(creds) #æˆæ¬Š"
      ],
      "metadata": {
        "id": "PLDvRT6crzGh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# é€£çµè©¦ç®—è¡¨\n",
        "sheet_url = \"https://docs.google.com/spreadsheets/d/1fGjPVqPHt3flo-LxBNU9EZl_ZMvg-I8UXfMhIY-jDNA/edit?usp=sharing\"  #GoogleSheeté€£çµ\n",
        "sh = gc.open_by_url(sheet_url)  #é€²å…¥è©¦ç®—è¡¨\n",
        "WORKSHEETS = {\n",
        "    \"novel\": sh.worksheet(\"å°èªªæ¸…å–®\"),\n",
        "    \"comic\": sh.worksheet(\"æ¼«ç•«æ¸…å–®\"),\n",
        "    \"anime\": sh.worksheet(\"å‹•ç•«æ¸…å–®\")\n",
        "}\n",
        "SNAPSHOT_SHEET = sh.worksheet(\"update_snapshot\")"
      ],
      "metadata": {
        "id": "S4lVAS3AtFL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# è®€å–è©¦ç®—è¡¨\n",
        "COLUMNS = [\"ID\", \"ä½œå“åç¨±\", \"ä½œè€…\", \"è©•ç´š\", \"é€²åº¦\", \"ç‹€æ…‹\", \"æœ€å¾Œç´€éŒ„æ—¥æœŸ\", \"æ›´æ–°ç¶²å€\"]  #è³‡æ–™åº«8æ¬„\n",
        "DISPLAY_COLUMNS = COLUMNS + [\"è·é›¢ä¸Šæ¬¡ç´€éŒ„(å¤©)\"] #é¡¯ç¤ºç”¨8æ¬„\n",
        "\n",
        "def R_D(media):\n",
        "    ws = WORKSHEETS[media]\n",
        "    records = ws.get_all_records()\n",
        "    df = pd.DataFrame(records)\n",
        "\n",
        "    if df.empty:\n",
        "        df = pd.DataFrame(columns=COLUMNS)\n",
        "\n",
        "    df[\"ID\"] = pd.to_numeric(df[\"ID\"], errors=\"coerce\")\n",
        "\n",
        "    def calc_days(d):\n",
        "        try:\n",
        "            return (datetime.date.today() - datetime.datetime.strptime(d, \"%Y/%m/%d\").date()).days\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    df[\"è·é›¢ä¸Šæ¬¡ç´€éŒ„(å¤©)\"] = df[\"æœ€å¾Œç´€éŒ„æ—¥æœŸ\"].apply(calc_days)\n",
        "    return df\n",
        "\n",
        "def read_data(media):\n",
        "  worksheet = WORKSHEETS[media]\n",
        "  records = worksheet.get_all_records()\n",
        "  df = pd.DataFrame(records)\n",
        "\n",
        "  if df.empty:\n",
        "    df = pd.DataFrame(columns=COLUMNS)\n",
        "\n",
        "  #ç¢ºä¿ID\n",
        "  if \"ID\" in df.columns:\n",
        "    df[\"ID\"] = pd.to_numeric(df[\"ID\"], errors=\"coerce\")\n",
        "\n",
        "  #è¨ˆç®—è·é›¢ä¸Šæ¬¡ç´€éŒ„æ™‚é–“\n",
        "  today = datetime.date.today()\n",
        "\n",
        "  def calc_days(date_str):\n",
        "    try:\n",
        "      last_date = datetime.datetime.strptime(date_str, \"%Y/%m/%d\").date()\n",
        "      return (today - last_date).days\n",
        "    except:\n",
        "      return None\n",
        "  df[\"è·é›¢ä¸Šæ¬¡ç´€éŒ„(å¤©)\"] = df[\"æœ€å¾Œç´€éŒ„æ—¥æœŸ\"].apply(calc_days)\n",
        "\n",
        "  return df\n",
        "# read_data(media)"
      ],
      "metadata": {
        "id": "kqapJXLtt5Xn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å¯«å›è©¦ç®—è¡¨\n",
        "def write_data(df, media):\n",
        "  worksheet = WORKSHEETS[media]\n",
        "  df = df[COLUMNS] #å¼·åˆ¶åªç•™ä¸‹è³‡æ–™åº«æ¬„ä½\n",
        "  worksheet.clear()\n",
        "  worksheet.append_row(COLUMNS)\n",
        "  worksheet.append_rows(df.values.tolist())\n",
        "# write_data(read_data())"
      ],
      "metadata": {
        "id": "b7aO5aDqWZ60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# æ–°å¢ç´€éŒ„\n",
        "def add_record(name, author, rating, progress, condition, date, media):\n",
        "  worksheet = WORKSHEETS[media]\n",
        "  df = read_data(media)\n",
        "  if not date:\n",
        "      date = datetime.date.today().strftime(\"%Y/%m/%d\")\n",
        "  if df.empty or df[\"ID\"].dropna().empty: #ç”¢ç”ŸID\n",
        "    new_id = 1\n",
        "  else:\n",
        "    new_id = int(df[\"ID\"].max()) + 1\n",
        "  new_entry = {\"ID\": new_id, \"ä½œå“åç¨±\": name, \"ä½œè€…\": author, \"è©•ç´š\": rating, \"é€²åº¦\": progress, \"ç‹€æ…‹\": condition, \"æœ€å¾Œç´€éŒ„æ—¥æœŸ\": date}\n",
        "  df = pd.concat([df, pd.DataFrame([new_entry])], ignore_index=True)\n",
        "  write_data(df, media)\n",
        "  return df\n",
        "\n",
        "# add_record(name=\"æ¸¬è©¦ä½œå“A\", author=\"æ¸¬è©¦ä½œè€…\", rating=\"B\", progress=\"ç¬¬1é›†\", condition=\"æœªå®Œçµ\", date=\"\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3IOJY-z1XIWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ä¿®æ”¹ç´€éŒ„\n",
        "def edit_record(record_id, name, author, rating, progress, condition, date, media):\n",
        "  worksheet = WORKSHEETS[media]\n",
        "  df = read_data(media)\n",
        "  if record_id not in df[\"ID\"].values:\n",
        "    return \"æ‰¾ä¸åˆ°æ­¤ ID\"\n",
        "  if not date:\n",
        "    date = datetime.date.today().strftime(\"%Y/%m/%d\")\n",
        "\n",
        "  df.loc[df[\"ID\"] == record_id, [\"ä½œå“åç¨±\", \"ä½œè€…\", \"è©•ç´š\", \"é€²åº¦\", \"ç‹€æ…‹\", \"æœ€å¾Œç´€éŒ„æ—¥æœŸ\"]] = \\\n",
        "      [name, author, rating, progress, condition, date]\n",
        "  write_data(df, media)\n",
        "  return df\n",
        "# edit_record(1, \"ä½œå“A-ä¿®æ­£\", \"ä½œè€…A\", \"A\", \"30\", \"æœªå®Œçµ\", \"\")"
      ],
      "metadata": {
        "id": "_1AsW6ENlGLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# åˆªé™¤ç´€éŒ„\n",
        "def delete_record(record_id, media):\n",
        "  worksheet = WORKSHEETS[media]\n",
        "  df = read_data()\n",
        "  if record_id not in df[\"ID\"].values:\n",
        "    return \"æ‰¾ä¸åˆ°æ­¤ ID\"\n",
        "  df = df[df[\"ID\"] != record_id]\n",
        "  write_data(df, media)\n",
        "  return df\n",
        "# delete_record(2)"
      ],
      "metadata": {
        "id": "e25t2TQIlbrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradioç”¨ æ”¹å‹•è¡¨å–®\n",
        "def save_table(table_df, media):\n",
        "  worksheet = WORKSHEETS[media]\n",
        "  df = pd.DataFrame(table_df, columns=DISPLAY_COLUMNS) # è½‰æˆDataFrameä¸¦å¼·åˆ¶æ¬„ä½é †åº\n",
        "  df = df[COLUMNS] #ä¸Ÿæ‰ç¬¬8æ¬„\n",
        "  df[\"ID\"] = range(1, len(df) + 1) #ä¿®æ­£IDï¼ˆé˜²æ­¢ä½¿ç”¨è€…äº‚æ”¹/åˆªåˆ—ï¼‰\n",
        "\n",
        "  today = datetime.date.today().strftime(\"%Y/%m/%d\")\n",
        "  df[\"æœ€å¾Œç´€éŒ„æ—¥æœŸ\"] = df[\"æœ€å¾Œç´€éŒ„æ—¥æœŸ\"].replace(\"\", today)\n",
        "  write_data(df, media)\n",
        "\n",
        "  return read_data(media)"
      ],
      "metadata": {
        "id": "Ry9yQncyUtl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradioç”¨ æ–°å¢è³‡æ–™åˆ—\n",
        "def add_empty_row(table_df, media):\n",
        "  worksheet = WORKSHEETS[media]\n",
        "  df = pd.DataFrame(table_df, columns=DISPLAY_COLUMNS)\n",
        "\n",
        "  new_row = {\n",
        "    \"ID\": \"\",\n",
        "    \"ä½œå“åç¨±\": \"\",\n",
        "    \"ä½œè€…\": \"\",\n",
        "    \"è©•ç´š\": \"\",\n",
        "    \"é€²åº¦\": \"\",\n",
        "    \"ç‹€æ…‹\": \"\",\n",
        "    \"æœ€å¾Œç´€éŒ„æ—¥æœŸ\": \"\",\n",
        "    \"è·é›¢ä¸Šæ¬¡ç´€éŒ„(å¤©)\": \"\"\n",
        "  }\n",
        "\n",
        "  df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "3YqST78LbWh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradioç”¨ åˆªé™¤è³‡æ–™åˆ—\n",
        "def delete_and_refresh(record_id, media):\n",
        "  #é˜²å‘†ID\n",
        "  if record_id is None:\n",
        "    return read_data(media)\n",
        "  try:\n",
        "    record_id = int(record_id)\n",
        "  except:\n",
        "    return read_data(media)\n",
        "\n",
        "  df = read_data(media)\n",
        "\n",
        "  if record_id not in df[\"ID\"].values:\n",
        "    return df\n",
        "\n",
        "  # åŸ·è¡Œåˆªé™¤\n",
        "  df = df[df[\"ID\"] != record_id].reset_index(drop=True)\n",
        "\n",
        "  # é˜²å‘†æ•´è¡¨è¢«æ¸…ç©º\n",
        "  if df.empty:\n",
        "    return df\n",
        "\n",
        "  #é‡æ’ID\n",
        "  df[\"ID\"] = range(1, len(df) + 1)\n",
        "\n",
        "  write_data(df, media)\n",
        "  return read_data(media)"
      ],
      "metadata": {
        "id": "08RW-qc7bzC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ç¤ºè­¦æ¸…å–®\n",
        "ALERT_RULES = {\n",
        "  \"novel\": 90, #å°èªª3å€‹æœˆ\n",
        "  \"comic\": 30, #æ¼«ç•«1å€‹æœˆ\n",
        "  \"anime\": 14 #å‹•ç•«14å¤©\n",
        "}\n",
        "ALERT_COLUMNS = [\n",
        "    \"ID\",\n",
        "    \"ä½œå“åç¨±\",\n",
        "    \"ä½œè€…\",\n",
        "    \"é€²åº¦\",\n",
        "    \"ç‹€æ…‹\",\n",
        "    \"æœ€å¾Œç´€éŒ„æ—¥æœŸ\",\n",
        "    \"è·é›¢ä¸Šæ¬¡ç´€éŒ„(å¤©)\"\n",
        "]\n",
        "\n",
        "def get_alert_table(media):\n",
        "  df = read_data(media)\n",
        "\n",
        "  if df.empty:\n",
        "      return df\n",
        "\n",
        "  threshold = ALERT_RULES[media]\n",
        "\n",
        "  alert_df = df[\n",
        "      (df[\"ç‹€æ…‹\"] == \"æœªå®Œçµ\") &\n",
        "      (df[\"è·é›¢ä¸Šæ¬¡ç´€éŒ„(å¤©)\"].notna()) &\n",
        "      (df[\"è·é›¢ä¸Šæ¬¡ç´€éŒ„(å¤©)\"] >= threshold)\n",
        "  ]\n",
        "\n",
        "  return alert_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Fp0KEcEC7Me4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# è·¨åª’é«”åµæ¸¬\n",
        "CROSS_MEDIA_CONFIG = {\n",
        "    \"novel\": {\n",
        "        \"targets\": [\"comic\", \"anime\"],\n",
        "        \"columns\": [\"å°æ‡‰æ¼«ç•«ID\", \"å°æ‡‰å‹•ç•«ID\"]\n",
        "    },\n",
        "    \"comic\": {\n",
        "        \"targets\": [\"novel\", \"anime\"],\n",
        "        \"columns\": [\"å°æ‡‰å°èªªID\", \"å°æ‡‰å‹•ç•«ID\"]\n",
        "    },\n",
        "    \"anime\": {\n",
        "        \"targets\": [\"novel\", \"comic\"],\n",
        "        \"columns\": [\"å°æ‡‰å°èªªID\", \"å°æ‡‰æ¼«ç•«ID\"]\n",
        "    }\n",
        "}\n",
        "def get_cross_columns(media):\n",
        "  return [\"ID\", \"ä½œå“åç¨±\"] + CROSS_MEDIA_CONFIG[media][\"columns\"]\n",
        "\n",
        "def build_cross_media_table(media):\n",
        "  base_df = read_data(media)\n",
        "\n",
        "  if base_df.empty:\n",
        "      return pd.DataFrame(columns=get_cross_columns(media))\n",
        "\n",
        "  targets = CROSS_MEDIA_CONFIG[media][\"targets\"]\n",
        "  target_dfs = {t: read_data(t) for t in targets}\n",
        "\n",
        "  rows = []\n",
        "\n",
        "  for _, row in base_df.iterrows():\n",
        "      title = row[\"ä½œå“åç¨±\"]\n",
        "      base_id = int(row[\"ID\"])\n",
        "\n",
        "      cross_ids = {}\n",
        "\n",
        "      for t in targets:\n",
        "          match = target_dfs[t][target_dfs[t][\"ä½œå“åç¨±\"] == title]\n",
        "          cross_ids[t] = int(match.iloc[0][\"ID\"]) if not match.empty else \"\"\n",
        "\n",
        "      # è‡³å°‘æœ‰ä¸€å€‹å°æ‡‰æ‰é¡¯ç¤º\n",
        "      if any(cross_ids.values()):\n",
        "          entry = {\n",
        "              \"ID\": base_id,\n",
        "              \"ä½œå“åç¨±\": title\n",
        "          }\n",
        "\n",
        "          for t, col_name in zip(targets, CROSS_MEDIA_CONFIG[media][\"columns\"]):\n",
        "              entry[col_name] = cross_ids[t]\n",
        "\n",
        "          rows.append(entry)\n",
        "\n",
        "  return pd.DataFrame(rows, columns=get_cross_columns(media))"
      ],
      "metadata": {
        "id": "Up8TaH3B_dM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#æŸ¥è©¢ç³»çµ±\n",
        "SEARCH_COLUMNS = [\n",
        "    \"ID\", \"ä½œå“åç¨±\", \"ä½œè€…\", \"è©•ç´š\", \"é€²åº¦\",\n",
        "    \"ç‹€æ…‹\", \"æœ€å¾Œç´€éŒ„æ—¥æœŸ\", \"è·é›¢ä¸Šæ¬¡ç´€éŒ„(å¤©)\", \"é¡å‹\"\n",
        "]\n",
        "def get_all_media_data():\n",
        "  dfs = []\n",
        "\n",
        "  for media, label in [\n",
        "      (\"novel\", \"å°èªª\"),\n",
        "      (\"comic\", \"æ¼«ç•«\"),\n",
        "      (\"anime\", \"å‹•ç•«\")\n",
        "  ]:\n",
        "    df = read_data(media)\n",
        "    if df.empty:\n",
        "        continue\n",
        "\n",
        "    df = df.copy()\n",
        "    df[\"é¡å‹\"] = label\n",
        "    dfs.append(df)\n",
        "\n",
        "  if not dfs:\n",
        "    return pd.DataFrame(columns=SEARCH_COLUMNS)\n",
        "\n",
        "  return pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "def search_works(keyword, rating, status, min_days):\n",
        "  df = get_all_media_data()\n",
        "\n",
        "  if df.empty:\n",
        "      return df\n",
        "\n",
        "  # é—œéµå­—æœå°‹ï¼ˆID / ä½œå“ / ä½œè€…ï¼‰\n",
        "  if keyword:\n",
        "    keyword = str(keyword).strip()\n",
        "    df = df[\n",
        "      df[\"ä½œå“åç¨±\"].astype(str).str.contains(keyword, case=False, na=False) |\n",
        "      df[\"ä½œè€…\"].astype(str).str.contains(keyword, case=False, na=False) |\n",
        "      df[\"ID\"].astype(str).str.contains(keyword, na=False)\n",
        "    ]\n",
        "\n",
        "  # è©•ç´šç¯©é¸\n",
        "  if rating != \"å…¨éƒ¨\":\n",
        "    df = df[df[\"è©•ç´š\"] == rating]\n",
        "\n",
        "  # ç‹€æ…‹ç¯©é¸\n",
        "  if status != \"å…¨éƒ¨\":\n",
        "    df = df[df[\"ç‹€æ…‹\"] == status]\n",
        "\n",
        "  # è·é›¢ä¸Šæ¬¡ç´€éŒ„\n",
        "  if min_days is not None:\n",
        "    df = df[df[\"è·é›¢ä¸Šæ¬¡ç´€éŒ„(å¤©)\"] >= min_days]\n",
        "\n",
        "  return df[SEARCH_COLUMNS]"
      ],
      "metadata": {
        "id": "RnzGRCqrC-9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TD():\n",
        "    return datetime.date.today().strftime(\"%Y/%m/%d\")\n",
        "def W_D(df, media):\n",
        "    ws = WORKSHEETS[media]\n",
        "    ws.clear()\n",
        "    ws.append_row(COLUMNS)\n",
        "    if not df.empty:\n",
        "        ws.append_rows(df[COLUMNS].values.tolist())\n",
        "# ---------- Snapshot ----------\n",
        "def load_snapshot():\n",
        "    records = SNAPSHOT_SHEET.get_all_records()\n",
        "    if not records:\n",
        "        return pd.DataFrame(columns=[\"åª’é«”\", \"ID\", \"ä½œå“åç¨±\", \"é€²åº¦\"])\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def save_snapshot(df):\n",
        "    SNAPSHOT_SHEET.clear()\n",
        "    SNAPSHOT_SHEET.append_row([\"åª’é«”\", \"ID\", \"ä½œå“åç¨±\", \"é€²åº¦\"])\n",
        "    if not df.empty:\n",
        "        SNAPSHOT_SHEET.append_rows(df.values.tolist())\n",
        "\n",
        "\n",
        "# ---------- Parser ----------\n",
        "CHINESE_NUM_MAP = {\n",
        "    \"é›¶\": 0,\n",
        "    \"ä¸€\": 1,\n",
        "    \"äºŒ\": 2,\n",
        "    \"ä¸‰\": 3,\n",
        "    \"å››\": 4,\n",
        "    \"äº”\": 5,\n",
        "    \"å…­\": 6,\n",
        "    \"ä¸ƒ\": 7,\n",
        "    \"å…«\": 8,\n",
        "    \"ä¹\": 9,\n",
        "    \"å\": 10\n",
        "}\n",
        "\n",
        "def chinese_to_int(s):\n",
        "    # åªè™•ç† 1ï½99 å·ï¼ˆå°è¼•å°èªªå®Œå…¨å¤ ç”¨ï¼‰\n",
        "    if s.isdigit():\n",
        "        return int(s)\n",
        "\n",
        "    if s == \"å\":\n",
        "        return 10\n",
        "    if s.startswith(\"å\"):\n",
        "        return 10 + CHINESE_NUM_MAP.get(s[1], 0)\n",
        "    if s.endswith(\"å\"):\n",
        "        return CHINESE_NUM_MAP.get(s[0], 0) * 10\n",
        "    if \"å\" in s:\n",
        "        a, b = s.split(\"å\")\n",
        "        return CHINESE_NUM_MAP.get(a, 0) * 10 + CHINESE_NUM_MAP.get(b, 0)\n",
        "\n",
        "    return CHINESE_NUM_MAP.get(s, 0)\n",
        "\n",
        "\n",
        "def parse_lnovel(url):\n",
        "    try:\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "        resp = requests.get(url, headers=headers, timeout=10)\n",
        "        resp.encoding = \"utf-8\"\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "        volumes = []\n",
        "\n",
        "        for text in soup.stripped_strings:\n",
        "            text = text.strip()\n",
        "\n",
        "            # âœ… æ ¸å¿ƒï¼šæŠ“ã€Œç¬¬Xå·ã€ï¼ŒX å¯ç‚ºä¸­æ–‡æˆ–æ•¸å­—\n",
        "            m = re.search(r\"ç¬¬\\s*([é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\\d]+)\\s*å·\", text)\n",
        "            if m:\n",
        "                raw = m.group(1)\n",
        "                num = chinese_to_int(raw)\n",
        "                if num > 0:\n",
        "                    volumes.append(num)\n",
        "\n",
        "        if not volumes:\n",
        "            return \"æœªçŸ¥\"\n",
        "\n",
        "        latest = max(volumes)\n",
        "        return f\"ç¬¬{latest}å·\"\n",
        "\n",
        "    except Exception:\n",
        "        return \"æœªçŸ¥\"\n",
        "\n",
        "def parse_manhuagui(url):\n",
        "    try:\n",
        "        soup = BeautifulSoup(requests.get(url, timeout=10).text, \"html.parser\")\n",
        "        chapters = soup.select(\".chapter-list a\")\n",
        "        if chapters:\n",
        "            return chapters[0].text.strip()\n",
        "        return \"æœªçŸ¥\"\n",
        "    except:\n",
        "        return \"æœªçŸ¥\"\n",
        "\n",
        "\n",
        "def parse_bahamut(url):\n",
        "    return \"è«‹æ‰‹å‹•æ›´æ–°\"\n",
        "CHINESE_NUM = \"é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\"\n",
        "\n",
        "def parse_wenku8(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0\"\n",
        "        }\n",
        "\n",
        "        # ğŸ” reader.php â†’ index.php\n",
        "        if \"reader.php\" in url:\n",
        "            aid = re.search(r\"aid=(\\d+)\", url)\n",
        "            if aid:\n",
        "                url = f\"https://www.wenku8.net/modules/article/index.php?aid={aid.group(1)}\"\n",
        "\n",
        "        resp = requests.get(url, headers=headers, timeout=10)\n",
        "        resp.encoding = \"gbk\"  # â­ wenku8 æ˜¯ GBK ç·¨ç¢¼\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "        chapters = []\n",
        "\n",
        "        # ç« ç¯€é€£çµæ ¼å¼ï¼šç¬¬XXXç« \n",
        "        for a in soup.select(\"a\"):\n",
        "            text = a.get_text(strip=True)\n",
        "\n",
        "            if re.match(r\"ç¬¬\\s*\\d+\\s*ç« \", text):\n",
        "                chapters.append(text)\n",
        "\n",
        "        if not chapters:\n",
        "            return \"æœªçŸ¥\"\n",
        "\n",
        "        # wenku8 æ˜¯ã€ŒèˆŠ â†’ æ–°ã€æ’åˆ—ï¼Œå–æœ€å¾Œä¸€ç« \n",
        "        return chapters[-1]\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"æœªçŸ¥\"\n",
        "\n",
        "def parse_linovelib(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0\"\n",
        "        }\n",
        "\n",
        "        resp = requests.get(url, headers=headers, timeout=10)\n",
        "        resp.encoding = resp.apparent_encoding\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "        # linovelib æœ€æ–°ç« ç¯€é€šå¸¸åœ¨ã€Œæœ€æ–°ç« ç¯€ã€å€å¡Š\n",
        "        # å¸¸è¦‹æ ¼å¼ï¼šç¬¬XXXè©± / ç¬¬XXXç« \n",
        "        for text in soup.stripped_strings:\n",
        "            if re.match(r\"ç¬¬\\s*\\d+\\s*[è©±ç« ]\", text):\n",
        "                return text.strip()\n",
        "\n",
        "        return \"æœªçŸ¥\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"æœªçŸ¥\"\n",
        "\n",
        "def parse_update_date(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0\"\n",
        "        }\n",
        "        html = requests.get(url, headers=headers, timeout=10).text\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "        # å¸¸è¦‹æ›´æ–°æ—¥æœŸæ–‡å­—\n",
        "        for text in soup.stripped_strings:\n",
        "            if \"æ›´æ–°\" in text and any(c.isdigit() for c in text):\n",
        "                return text.strip()\n",
        "\n",
        "        return \"æœªçŸ¥\"\n",
        "    except:\n",
        "        return \"æœªçŸ¥\"\n",
        "\n",
        "def parse_generic(url):\n",
        "    try:\n",
        "        soup = BeautifulSoup(requests.get(url, timeout=10).text, \"html.parser\")\n",
        "        for t in soup.stripped_strings:\n",
        "            if any(k in t.lower() for k in [\"è©±\", \"é›†\", \"ç« \", \"ep\", \"episode\"]) and len(t) <= 15:\n",
        "                return t.strip()\n",
        "        return \"æœªçŸ¥\"\n",
        "    except:\n",
        "        return \"æœªçŸ¥\"\n",
        "\n",
        "\n",
        "PARSERS = {\n",
        "    \"manhuagui.com\": parse_manhuagui,\n",
        "    \"www.manhuagui.com\": parse_manhuagui,\n",
        "    \"ani.gamer.com.tw\": parse_bahamut,\n",
        "    \"wenku8.net\": parse_wenku8,\n",
        "    \"www.wenku8.net\": parse_wenku8,\n",
        "    \"tw.linovelib.com\": parse_linovelib,\n",
        "    \"www.linovelib.com\": parse_linovelib,\n",
        "    \"lnovel.tw\": parse_lnovel,\n",
        "    \"www.lnovel.tw\": parse_lnovel,\n",
        "}\n",
        "\n",
        "\n",
        "def get_domain(url):\n",
        "    try:\n",
        "        return url.split(\"//\")[1].split(\"/\")[0]\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def get_latest_from_url(url, debug=True):\n",
        "    domain = get_domain(url)\n",
        "\n",
        "    if debug:\n",
        "        print(f\"[DEBUG] URL = {url}\")\n",
        "        print(f\"[DEBUG] domain = {domain}\")\n",
        "\n",
        "    parser = PARSERS.get(domain)\n",
        "\n",
        "    if not parser:\n",
        "        if debug:\n",
        "            print(\"[DEBUG] âŒ No parser found for this domain\")\n",
        "        return \"æœªçŸ¥\"\n",
        "\n",
        "    if debug:\n",
        "        print(f\"[DEBUG] âœ… Using parser: {parser.__name__}\")\n",
        "\n",
        "    try:\n",
        "        result = parser(url)\n",
        "\n",
        "        if debug:\n",
        "            print(f\"[DEBUG] ğŸ“¤ Parser result = {result}\")\n",
        "\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        if debug:\n",
        "            print(f\"[DEBUG] ğŸ’¥ Parser exception: {e}\")\n",
        "        return \"æœªçŸ¥\"\n",
        "\n",
        "# ---------- æ›´æ–°æª¢æŸ¥ ----------\n",
        "def detect_updates(media):\n",
        "    df = R_D(media)\n",
        "    snapshot = load_snapshot()\n",
        "    alerts = []\n",
        "    new_rows = []\n",
        "\n",
        "    for _, r in df.iterrows():\n",
        "        cid = str(r[\"ID\"])\n",
        "        title = r[\"ä½œå“åç¨±\"]\n",
        "        latest = get_latest_from_url(r.get(\"æ›´æ–°ç¶²å€\", \"\"))\n",
        "\n",
        "        snap = snapshot[(snapshot[\"åª’é«”\"] == media) & (snapshot[\"ID\"] == cid)]\n",
        "        old = r[\"é€²åº¦\"]\n",
        "\n",
        "        if latest != \"æœªçŸ¥\" and latest != old:\n",
        "            alerts.append(f\"{title}ï¼š{old} â†’ {latest}\")\n",
        "            df.loc[df[\"ID\"] == int(cid), \"é€²åº¦\"] = latest\n",
        "            df.loc[df[\"ID\"] == int(cid), \"æœ€å¾Œç´€éŒ„æ—¥æœŸ\"] = TD()\n",
        "            new_rows.append([media, cid, title, latest])\n",
        "        else:\n",
        "            new_rows.append([media, cid, title, old])\n",
        "\n",
        "    #W_D(df, media)\n",
        "    save_snapshot(pd.concat([\n",
        "        snapshot[snapshot[\"åª’é«”\"] != media],\n",
        "        pd.DataFrame(new_rows, columns=[\"åª’é«”\", \"ID\", \"ä½œå“åç¨±\", \"é€²åº¦\"])\n",
        "    ], ignore_index=True))\n",
        "\n",
        "    return alerts\n",
        "def get_gradio_alerts():\n",
        "    msgs = []\n",
        "    for m, label in [(\"novel\", \"å°èªª\"), (\"comic\", \"æ¼«ç•«\"), (\"anime\", \"å‹•ç•«\")]:\n",
        "        for a in detect_updates(m):\n",
        "            msgs.append(f\"- {label}ï½œ{a}\")\n",
        "    return \"âœ… ç›®å‰æ²’æœ‰æ›´æ–°\" if not msgs else \"ğŸ“¢ **æ›´æ–°æª¢æŸ¥çµæœ**\\n\\n\" + \"\\n\".join(msgs)\n",
        "#======================================= for testing pur =============================================\n",
        "#print(get_latest_from_url(\"https://lnovel.tw/books-1279\"))\n",
        "#print(parse_lnovel(\"https://lnovel.tw/books-1279\"))\n",
        "def diagnose_parser(url):\n",
        "    report = {\n",
        "        \"url\": str(url).strip(),\n",
        "        \"domain\": \"\",\n",
        "        \"parser\": None,\n",
        "        \"status\": \"OK\",\n",
        "        \"result\": None,\n",
        "        \"reason\": \"\"\n",
        "    }\n",
        "\n",
        "    if not report[\"url\"]:\n",
        "        report[\"status\"] = \"FAIL\"\n",
        "        report[\"reason\"] = \"ç¶²å€ç‚ºç©º\"\n",
        "        return report\n",
        "\n",
        "    # è§£æ domain\n",
        "    try:\n",
        "        report[\"domain\"] = get_domain(report[\"url\"])\n",
        "    except Exception:\n",
        "        report[\"status\"] = \"FAIL\"\n",
        "        report[\"reason\"] = \"ç¶²å€æ ¼å¼éŒ¯èª¤\"\n",
        "        return report\n",
        "\n",
        "    # æ‰¾ parser\n",
        "    parser = PARSERS.get(report[\"domain\"])\n",
        "    if not parser:\n",
        "        report[\"status\"] = \"FAIL\"\n",
        "        report[\"reason\"] = \"æ‰¾ä¸åˆ°å°æ‡‰çš„ Parser\"\n",
        "        return report\n",
        "\n",
        "    report[\"parser\"] = parser.__name__\n",
        "\n",
        "    # å¯¦éš›åŸ·è¡Œ parser\n",
        "    try:\n",
        "        result = parser(report[\"url\"])\n",
        "        report[\"result\"] = result\n",
        "\n",
        "        if not result or result == \"æœªçŸ¥\":\n",
        "            report[\"status\"] = \"FAIL\"\n",
        "            report[\"reason\"] = \"Parser æœ‰åŸ·è¡Œï¼Œä½†æŠ“ä¸åˆ°ç« ç¯€ï¼ˆæ­£å‰‡æœªå‘½ä¸­ï¼‰\"\n",
        "        else:\n",
        "            report[\"status\"] = \"OK\"\n",
        "\n",
        "    except Exception as e:\n",
        "        report[\"status\"] = \"FAIL\"\n",
        "        report[\"reason\"] = f\"Parser åŸ·è¡Œä¾‹å¤–ï¼š{e}\"\n",
        "\n",
        "    return report\n",
        "def diagnose_novel_parsers():\n",
        "    df = read_data(\"novel\")\n",
        "\n",
        "    reports = []\n",
        "\n",
        "    for _, r in df.iterrows():\n",
        "        diag = diagnose_parser(r.get(\"æ›´æ–°ç¶²å€\", \"\"))\n",
        "        diag[\"ID\"] = r[\"ID\"]\n",
        "        diag[\"ä½œå“åç¨±\"] = r[\"ä½œå“åç¨±\"]\n",
        "        diag[\"ç›®å‰é€²åº¦\"] = r[\"é€²åº¦\"]\n",
        "        reports.append(diag)\n",
        "\n",
        "    return pd.DataFrame(reports, columns=[\n",
        "        \"ID\",\n",
        "        \"ä½œå“åç¨±\",\n",
        "        \"ç›®å‰é€²åº¦\",\n",
        "        \"url\",\n",
        "        \"domain\",\n",
        "        \"parser\",\n",
        "        \"status\",\n",
        "        \"reason\",\n",
        "        \"result\"\n",
        "    ])\n",
        "#diagnose_parser(\"https://lnovel.tw/books-1279\")\n",
        "\n",
        "#print(parse_lnovel(\"https://lnovel.tw/books-1279\"))\n",
        "#for t in list(BeautifulSoup(\n",
        "    #requests.get(\"https://lnovel.tw/books-1279\").text,\n",
        "    #\"html.parser\"\n",
        "#).stripped_strings)[:50]:\n",
        "    #print(repr(t))"
      ],
      "metadata": {
        "id": "dwuH0KGOcc3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "#gradioæ“ä½œä»‹é¢\n",
        "with gr.Blocks() as app:\n",
        "  gr.Markdown(\"è¿½ç•ªæ¸…å–®\")\n",
        "  with gr.Tab(\"å°èªªæ¸…å–®\"): #åˆ†é \n",
        "    gr.Markdown(\"ç›´æ¥ç·¨è¼¯æ¸…å–®å¾Œé»æ“Šå„²å­˜æ›´è®Šå³å¯å„²å­˜!\")\n",
        "    refresh_novel = gr.Button(\"é‡æ–°æ•´ç†\") #åˆ·æ–°æŒ‰éˆ•\n",
        "    with gr.Row():\n",
        "      add_novel = gr.Button(\"æ–°å¢ä¸€ç­†\")\n",
        "      del_novel_id = gr.Number(label=\"åˆªé™¤ ID\", precision=0)\n",
        "      del_novel = gr.Button(\"åˆªé™¤è©²ç­†\", variant=\"stop\")\n",
        "    save_novel = gr.Button(\"å„²å­˜è®Šæ›´\", variant=\"secondary\")\n",
        "\n",
        "    table_novel = gr.Dataframe( #è¡¨å–®\n",
        "      value=read_data(\"novel\"),\n",
        "      headers=COLUMNS,\n",
        "      interactive=True\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"ç³»çµ±åµæ¸¬åˆ°ä»¥ä¸‹ä½œå“å­˜åœ¨è·¨åª’é«”\")\n",
        "    cross_table_novel = gr.Dataframe(\n",
        "        value=build_cross_media_table(\"novel\"),\n",
        "        headers=get_cross_columns(\"novel\"),\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    refresh_novel.click(fn=lambda: read_data(\"novel\"), outputs=table_novel)\n",
        "    add_novel.click(\n",
        "        fn=lambda table: add_empty_row(table, \"novel\"),\n",
        "        inputs=table_novel,\n",
        "        outputs=table_novel\n",
        "    )\n",
        "    del_novel.click(\n",
        "      fn=lambda rid: delete_and_refresh(rid, \"novel\"),\n",
        "      inputs=del_novel_id,\n",
        "      outputs=table_novel\n",
        "    )\n",
        "\n",
        "    save_novel.click(\n",
        "        fn=lambda table: save_table(table, \"novel\"),\n",
        "        inputs=table_novel,\n",
        "        outputs=table_novel\n",
        "    )\n",
        "\n",
        "  with gr.Tab(\"æ¼«ç•«æ¸…å–®\"):\n",
        "    gr.Markdown(\"ç›´æ¥ç·¨è¼¯æ¸…å–®å¾Œé»æ“Šå„²å­˜æ›´è®Šå³å¯å„²å­˜!\")\n",
        "    refresh_comic = gr.Button(\"é‡æ–°æ•´ç†\") #åˆ·æ–°æŒ‰éˆ•\n",
        "    with gr.Row():\n",
        "      add_comic = gr.Button(\"æ–°å¢ä¸€ç­†\")\n",
        "      del_comic_id = gr.Number(label=\"åˆªé™¤ ID\", precision=0)\n",
        "      del_comic = gr.Button(\"åˆªé™¤è©²ç­†\", variant=\"stop\")\n",
        "    save_comic = gr.Button(\"å„²å­˜è®Šæ›´\", variant=\"secondary\")\n",
        "\n",
        "    table_comic = gr.Dataframe( #è¡¨å–®\n",
        "      value=read_data(\"comic\"),\n",
        "      headers=COLUMNS,\n",
        "      interactive=True\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"ç³»çµ±åµæ¸¬åˆ°ä»¥ä¸‹ä½œå“å­˜åœ¨è·¨åª’é«”\")\n",
        "    cross_table_comic = gr.Dataframe(\n",
        "        value=build_cross_media_table(\"comic\"),\n",
        "        headers=get_cross_columns(\"comic\"),\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    refresh_comic.click(fn=lambda: read_data(\"comic\"), outputs=table_comic)\n",
        "    add_comic.click(\n",
        "        fn=lambda table: add_empty_row(table, \"comic\"),\n",
        "        inputs=table_comic,\n",
        "        outputs=table_comic\n",
        "    )\n",
        "    del_comic.click(\n",
        "      fn=lambda rid: delete_and_refresh(rid, \"comic\"),\n",
        "      inputs=del_comic_id,\n",
        "      outputs=table_comic\n",
        "    )\n",
        "\n",
        "    save_comic.click(\n",
        "        fn=lambda table: save_table(table, \"comic\"),\n",
        "        inputs=table_comic,\n",
        "        outputs=table_comic\n",
        "    )\n",
        "\n",
        "  with gr.Tab(\"å‹•ç•«æ¸…å–®\"):\n",
        "    gr.Markdown(\"ç›´æ¥ç·¨è¼¯æ¸…å–®å¾Œé»æ“Šå„²å­˜æ›´è®Šå³å¯å„²å­˜!\")\n",
        "    refresh_anime = gr.Button(\"é‡æ–°æ•´ç†\") #åˆ·æ–°æŒ‰éˆ•\n",
        "    with gr.Row():\n",
        "      add_anime = gr.Button(\"æ–°å¢ä¸€ç­†\")\n",
        "      del_anime_id = gr.Number(label=\"åˆªé™¤ ID\", precision=0)\n",
        "      del_anime = gr.Button(\"åˆªé™¤è©²ç­†\", variant=\"stop\")\n",
        "    save_anime = gr.Button(\"å„²å­˜è®Šæ›´\", variant=\"secondary\")\n",
        "\n",
        "    table_anime = gr.Dataframe( #è¡¨å–®\n",
        "      value=read_data(\"anime\"),\n",
        "      headers=COLUMNS,\n",
        "      interactive=True\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"ç³»çµ±åµæ¸¬åˆ°ä»¥ä¸‹ä½œå“å­˜åœ¨è·¨åª’é«”\")\n",
        "    cross_table_anime = gr.Dataframe(\n",
        "        value=build_cross_media_table(\"anime\"),\n",
        "        headers=get_cross_columns(\"anime\"),\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    refresh_anime.click(fn=lambda: read_data(\"anime\"), outputs=table_anime)\n",
        "    add_anime.click(\n",
        "        fn=lambda table: add_empty_row(table, \"anime\"),\n",
        "        inputs=table_anime,\n",
        "        outputs=table_anime\n",
        "    )\n",
        "    del_anime.click(\n",
        "      fn=lambda rid: delete_and_refresh(rid, \"anime\"),\n",
        "      inputs=del_anime_id,\n",
        "      outputs=table_anime\n",
        "    )\n",
        "\n",
        "    save_anime.click(\n",
        "        fn=lambda table: save_table(table, \"anime\"),\n",
        "        inputs=table_anime,\n",
        "        outputs=table_anime\n",
        "    )\n",
        "\n",
        "  with gr.Tab(\"ç¤ºè­¦æ¸…å–®\"):\n",
        "    gr.Markdown(\"åƒ…é¡¯ç¤ºã€Œæœªå®Œçµã€ä¸”é•·æ™‚é–“æœªæ›´æ–°çš„ä½œå“\")\n",
        "\n",
        "    alert_refresh = gr.Button(\"é‡æ–°æ•´ç†ç¤ºè­¦æ¸…å–®\")\n",
        "\n",
        "    gr.Markdown(\"å°èªªç¤ºè­¦ï¼ˆè¶…é 3 å€‹æœˆï¼‰\")\n",
        "    alert_novel = gr.Dataframe(\n",
        "        value=get_alert_table(\"novel\"),\n",
        "        headers=ALERT_COLUMNS,\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"æ¼«ç•«ç¤ºè­¦ï¼ˆè¶…é 1 å€‹æœˆï¼‰\")\n",
        "    alert_comic = gr.Dataframe(\n",
        "        value=get_alert_table(\"comic\"),\n",
        "        headers=ALERT_COLUMNS,\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"å‹•ç•«ç¤ºè­¦ï¼ˆè¶…é 14 å¤©ï¼‰\")\n",
        "    alert_anime = gr.Dataframe(\n",
        "        value=get_alert_table(\"anime\"),\n",
        "        headers=ALERT_COLUMNS,\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    alert_refresh.click(\n",
        "      fn=lambda: (\n",
        "          get_alert_table(\"novel\"),\n",
        "          get_alert_table(\"comic\"),\n",
        "          get_alert_table(\"anime\")\n",
        "      ),\n",
        "      outputs=[alert_novel, alert_comic, alert_anime]\n",
        "    )\n",
        "\n",
        "  with gr.Tab(\"æŸ¥è©¢ç³»çµ±\"):\n",
        "    gr.Markdown(\"### è·¨åª’é«”ä½œå“æŸ¥è©¢\")\n",
        "\n",
        "    with gr.Row():\n",
        "      keyword = gr.Textbox(label=\"é—œéµå­—ï¼ˆID / ä½œå“åç¨± / ä½œè€…ï¼‰\")\n",
        "      rating = gr.Dropdown(\n",
        "        choices=[\"å…¨éƒ¨\", \"S\", \"A\", \"B\", \"C\"],\n",
        "        value=\"å…¨éƒ¨\",\n",
        "        label=\"è©•ç´š\"\n",
        "      )\n",
        "      status = gr.Dropdown(\n",
        "        choices=[\"å…¨éƒ¨\", \"æœªå®Œçµ\", \"å®Œçµ\"],\n",
        "        value=\"å…¨éƒ¨\",\n",
        "        label=\"ç‹€æ…‹\"\n",
        "      )\n",
        "      min_days = gr.Number(\n",
        "        label=\"è·é›¢ä¸Šæ¬¡ç´€éŒ„ â‰¥ N å¤©\",\n",
        "        precision=0\n",
        "      )\n",
        "\n",
        "    search_btn = gr.Button(\"æŸ¥è©¢\")\n",
        "\n",
        "    search_table = gr.Dataframe(\n",
        "      headers=SEARCH_COLUMNS,\n",
        "      interactive=False\n",
        "    )\n",
        "\n",
        "    search_btn.click(\n",
        "      fn=search_works,\n",
        "      inputs=[keyword, rating, status, min_days],\n",
        "      outputs=search_table\n",
        "    )\n",
        "  with gr.Tab(\"æ›´æ–°æé†’\"):\n",
        "      out = gr.Markdown()\n",
        "      gr.Button(\"æª¢æŸ¥æ›´æ–°\").click(get_gradio_alerts, outputs=out)\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "HcRNpUznQfMp",
        "outputId": "8817575e-5664-490f-a902-03eba0cb8ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://907d0d020c8590ea2e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://907d0d020c8590ea2e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VaKgIXyEvC0W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}